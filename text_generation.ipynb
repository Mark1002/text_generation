{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from gensim.models import word2vec\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customizing plots with style \n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "rcParams['lines.linewidth'] = 2\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入文字資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 收集自維基百科\n",
    "with open(\"data/ref_text_tw.txt\", \"r\", encoding=\"utf-8\") as content:\n",
    "    document_list = [line.strip().replace(' ', '') for line in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['美希迪波路治一般稱作波路治，生於達爾貝達，摩洛哥職業足球運動員，現效力於美國職業足球大聯盟球會科羅拉多急流。', '羅利科隆出生於紐西蘭北島東北部吉斯伯恩，是一名英式足球足球運動員，司職前鋒前鋒，現時效力英甲球會斯坎索普聯足球俱樂部斯肯索普。', '他的機器實際上是在美國人口調查局的合約下完成的，製成後被用於1890年美國人口普查，普查工作因此得以在一年之內完成。', '石崎傳蔵，超級人瑞，曾是日本史上最年長男性。', '施世範，施琅第八子，襲封靖海侯。']\n",
      "total document num: 33868\n"
     ]
    }
   ],
   "source": [
    "print(document_list[:5])\n",
    "print(\"total document num: {}\".format(len(document_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 結巴分詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/mark/Documents/python/nlp-experiment/data/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.uf13363f31a3360411b43fe8e84af1634.cache\n",
      "Loading model cost 1.279 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# 用來存放分詞後的結果\n",
    "preprocessed_documents = []\n",
    "# stopword\n",
    "with open(\"data/jieba_dict/stopwords.txt\") as stop_words:\n",
    "    stop_word_list = [stop_word.strip() for stop_word in stop_words]\n",
    "# 支援繁體中文較好的詞庫\n",
    "jieba.set_dictionary(\"data/jieba_dict/dict.txt.big\")\n",
    "for document in document_list:\n",
    "    # preprocessed_document = list(filter(lambda x: x not in stop_word_list, list(jieba.cut(document))))\n",
    "    preprocessed_document = list(jieba.cut(document))\n",
    "    preprocessed_documents.append(preprocessed_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['美希迪波',\n",
       "  '路治',\n",
       "  '一般',\n",
       "  '稱作',\n",
       "  '波路治',\n",
       "  '，',\n",
       "  '生於',\n",
       "  '達爾貝',\n",
       "  '達',\n",
       "  '，',\n",
       "  '摩洛哥',\n",
       "  '職業',\n",
       "  '足球',\n",
       "  '運動員',\n",
       "  '，',\n",
       "  '現',\n",
       "  '效力',\n",
       "  '於',\n",
       "  '美國',\n",
       "  '職業',\n",
       "  '足球',\n",
       "  '大',\n",
       "  '聯盟',\n",
       "  '球會',\n",
       "  '科羅拉多',\n",
       "  '急流',\n",
       "  '。'],\n",
       " ['羅利',\n",
       "  '科隆',\n",
       "  '出',\n",
       "  '生於',\n",
       "  '紐西蘭',\n",
       "  '北島',\n",
       "  '東北部',\n",
       "  '吉斯',\n",
       "  '伯恩',\n",
       "  '，',\n",
       "  '是',\n",
       "  '一名',\n",
       "  '英式足球',\n",
       "  '足球',\n",
       "  '運動員',\n",
       "  '，',\n",
       "  '司職',\n",
       "  '前鋒',\n",
       "  '前鋒',\n",
       "  '，',\n",
       "  '現時',\n",
       "  '效力',\n",
       "  '英甲',\n",
       "  '球會',\n",
       "  '斯坎索',\n",
       "  '普聯',\n",
       "  '足球',\n",
       "  '俱樂部',\n",
       "  '斯肯',\n",
       "  '索普',\n",
       "  '。'],\n",
       " ['他',\n",
       "  '的',\n",
       "  '機器',\n",
       "  '實際上',\n",
       "  '是',\n",
       "  '在',\n",
       "  '美國',\n",
       "  '人口',\n",
       "  '調查局',\n",
       "  '的',\n",
       "  '合約',\n",
       "  '下',\n",
       "  '完成',\n",
       "  '的',\n",
       "  '，',\n",
       "  '製成',\n",
       "  '後',\n",
       "  '被',\n",
       "  '用於',\n",
       "  '1890',\n",
       "  '年',\n",
       "  '美國',\n",
       "  '人口普查',\n",
       "  '，',\n",
       "  '普查',\n",
       "  '工作',\n",
       "  '因此',\n",
       "  '得以',\n",
       "  '在',\n",
       "  '一年',\n",
       "  '之內',\n",
       "  '完成',\n",
       "  '。'],\n",
       " ['石崎傳',\n",
       "  '蔵',\n",
       "  '，',\n",
       "  '超級',\n",
       "  '人瑞',\n",
       "  '，',\n",
       "  '曾',\n",
       "  '是',\n",
       "  '日本',\n",
       "  '史上',\n",
       "  '最',\n",
       "  '年長',\n",
       "  '男性',\n",
       "  '。'],\n",
       " ['施世範', '，', '施琅', '第八', '子', '，', '襲封', '靖海侯', '。']]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此即為分詞處理好的 corpus\n",
    "preprocessed_documents[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 word2vec 訓練詞向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(preprocessed_documents, min_count=1, window=10, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/anaconda3/envs/tensorflow/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('中國國民黨', 0.9670590162277222),\n",
       " ('行政院長', 0.959876298904419),\n",
       " ('陳水扁', 0.952601432800293),\n",
       " ('中央委員會', 0.9520695805549622),\n",
       " ('嚴家淦', 0.9485561847686768),\n",
       " ('李光耀', 0.9444906711578369),\n",
       " ('開幕', 0.9424616694450378),\n",
       " ('中央政治局', 0.9411413073539734),\n",
       " ('楊尚昆', 0.9398090839385986),\n",
       " ('辦公室', 0.9372608065605164),\n",
       " ('黨內', 0.9358875155448914),\n",
       " ('立法委員', 0.9357191920280457),\n",
       " ('伉儷', 0.9349007606506348),\n",
       " ('政治局', 0.9313263893127441),\n",
       " ('委員長', 0.9309505224227905),\n",
       " ('副委員長', 0.9294939637184143),\n",
       " ('尤索夫', 0.9282247424125671),\n",
       " ('總統府', 0.9280449151992798),\n",
       " ('父親節', 0.9279723763465881),\n",
       " ('民進黨', 0.9277172684669495),\n",
       " ('立法院', 0.9265642762184143),\n",
       " ('連戰', 0.9255101680755615),\n",
       " ('第一夫人', 0.9246054887771606),\n",
       " ('壹', 0.9244298934936523),\n",
       " ('李顯龍', 0.9237725138664246),\n",
       " ('偕', 0.9236981868743896),\n",
       " ('鄧小平', 0.9235371947288513),\n",
       " ('中華人民共和國國務院', 0.9227968454360962),\n",
       " ('進步黨', 0.9222841858863831),\n",
       " ('臺灣省', 0.9220684170722961),\n",
       " ('中共中央政治局', 0.9215205907821655),\n",
       " ('朝鮮勞動黨', 0.9210669994354248),\n",
       " ('官邸', 0.9206576943397522),\n",
       " ('宋楚瑜', 0.9195537567138672),\n",
       " ('中央書記處', 0.9194828867912292),\n",
       " ('週刊', 0.918850839138031),\n",
       " ('鄧樸方', 0.9187365770339966),\n",
       " ('薄熙來', 0.9180949330329895),\n",
       " ('古蹟', 0.9180718660354614),\n",
       " ('溫哈熊', 0.9179619550704956),\n",
       " ('胡錦濤', 0.9177698493003845),\n",
       " ('最高法院', 0.9175732135772705),\n",
       " ('國務院', 0.9171569347381592),\n",
       " ('內閣', 0.9166384935379028),\n",
       " ('政務', 0.9150521755218506),\n",
       " ('中央軍委', 0.9149836897850037),\n",
       " ('國民政府', 0.9149770140647888),\n",
       " ('楚青', 0.9147542119026184),\n",
       " ('站臺', 0.9143924117088318),\n",
       " ('奧巴馬', 0.9137499332427979)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"李登輝\", topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/anaconda3/envs/tensorflow/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('王雅琦', 0.9662147760391235),\n",
       " ('林添', 0.9648601412773132),\n",
       " ('林覺民', 0.9632163047790527),\n",
       " ('吳江', 0.9624828100204468),\n",
       " ('女高音', 0.9593405723571777),\n",
       " ('工旦行', 0.9585226774215698),\n",
       " ('唐師曾', 0.9582151770591736),\n",
       " ('創意', 0.9576272964477539),\n",
       " ('水利學家', 0.956221878528595),\n",
       " ('莉莉', 0.9559784531593323),\n",
       " ('任佳藝', 0.9558889865875244),\n",
       " ('豹', 0.9558137655258179),\n",
       " ('歌唱家', 0.9556969404220581),\n",
       " ('宜蘭人', 0.9556719660758972),\n",
       " ('女藝員', 0.955659806728363),\n",
       " ('鳳儀', 0.9555197954177856),\n",
       " ('鄭文堂', 0.9552754163742065),\n",
       " ('流行歌曲', 0.9552042484283447),\n",
       " ('漫畫家', 0.9551963806152344),\n",
       " ('吳灘', 0.9549605846405029),\n",
       " ('喜劇演員', 0.9547865390777588),\n",
       " ('柯宇綸', 0.9545557498931885),\n",
       " ('蔡天鐸', 0.9545116424560547),\n",
       " ('刀郎', 0.9544733166694641),\n",
       " ('曹健', 0.954145610332489),\n",
       " ('麗', 0.9541454911231995),\n",
       " ('楊雅喆', 0.9537158012390137),\n",
       " ('薇薇安', 0.9533419013023376),\n",
       " ('英傑', 0.9527959823608398),\n",
       " ('實境秀', 0.9527789354324341),\n",
       " ('林子祥', 0.9516791105270386),\n",
       " ('戲曲', 0.951482355594635),\n",
       " ('鮑爾是', 0.9508172273635864),\n",
       " ('錢璐', 0.9503551125526428),\n",
       " ('宣萱', 0.9502129554748535),\n",
       " ('子為', 0.9499684572219849),\n",
       " ('泰之妻', 0.9499325752258301),\n",
       " ('何東', 0.9496227502822876),\n",
       " ('林翠', 0.9495601058006287),\n",
       " ('臺灣獨立', 0.9495123028755188),\n",
       " ('劉黎兒', 0.9494773149490356),\n",
       " ('曾國祥', 0.9494624733924866),\n",
       " ('嘉禾', 0.9493172764778137),\n",
       " ('劉美君', 0.9487254619598389),\n",
       " ('陳小藝', 0.9486340284347534),\n",
       " ('薛域', 0.9483606815338135),\n",
       " ('臺語', 0.9483070373535156),\n",
       " ('方平', 0.9481527209281921),\n",
       " ('契女', 0.9481444954872131),\n",
       " ('台北', 0.9476807117462158)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"男歌手\", topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(word):\n",
    "    return model.wv.vocab[word].index\n",
    "\n",
    "def idx2word(idx):\n",
    "    return model.wv.index2word[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 79279, embedding_size: 100\n",
      "Result embedding shape: (79279, 100)\n"
     ]
    }
   ],
   "source": [
    "# 檢視經過訓練出來之後的詞向量\n",
    "pretrained_weights = model.wv.vectors\n",
    "vocab_size, embedding_size = pretrained_weights.shape\n",
    "print(\"vocab_size: {}, embedding_size: {}\".format(vocab_size, embedding_size))\n",
    "print('Result embedding shape:', pretrained_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 構建語言生成 RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide window 用來控制學習的 seq 長度，size 越小，資料量越多，生成的文章會越有語意\n",
    "def slide_window(a, size):\n",
    "    window_list = []\n",
    "    for i in range(len(a)):\n",
    "        window = a[i:size+i]\n",
    "        if len(window) < size:\n",
    "            break\n",
    "        window_list.append(window)\n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_x_and_train_y(docs, max_doc_length):\n",
    "    seq_list = []\n",
    "    for doc in docs:\n",
    "        word_index_array = [word2idx(word) for word in doc]\n",
    "        window_list = slide_window(word_index_array, max_doc_length)\n",
    "        for window in window_list:\n",
    "            seq_list.append(window)\n",
    "    seq_list = np.array(seq_list)\n",
    "    train_x = seq_list[:,:-1]\n",
    "    train_y = seq_list[:,-1]\n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape: (779607, 2)\n",
      "train_y shape: (779607,)\n"
     ]
    }
   ],
   "source": [
    "# 構建訓練資料\n",
    "train_x, train_y = split_train_x_and_train_y(preprocessed_documents, 3)\n",
    "print('train_x shape:', train_x.shape)\n",
    "print('train_y shape:', train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    print('\\nGenerating text after epoch: %d' % epoch)\n",
    "    texts = [\"施世範\"]\n",
    "    for text in texts:\n",
    "        print('%s... -> %s' % (text, generate_next(texts, 10, 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 100)         7927900   \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 79279)             8007179   \n",
      "=================================================================\n",
      "Total params: 16,015,479\n",
      "Trainable params: 8,087,579\n",
      "Non-trainable params: 7,927,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model = Sequential()\n",
    "rnn_model.add(model.wv.get_keras_embedding())\n",
    "# rnn_model.add(LSTM(embedding_size, dropout=0.5, return_sequences=True))\n",
    "rnn_model.add(LSTM(embedding_size, dropout=0.5))\n",
    "rnn_model.add(Dense(units=vocab_size, activation=\"softmax\"))\n",
    "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623685 samples, validate on 155922 samples\n",
      "Epoch 1/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 8.0991\n",
      "Generating text after epoch: 0\n",
      "施世範... -> 施世範紂王。被是是在立即他的國家隊\n",
      "Epoch 00000: val_loss improved from inf to 7.61388, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 8.0992 - val_loss: 7.6139\n",
      "Epoch 2/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 7.2856\n",
      "Generating text after epoch: 1\n",
      "施世範... -> 施世範開始2012年月日日，他，在\n",
      "Epoch 00001: val_loss improved from 7.61388 to 7.25977, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 108s - loss: 7.2856 - val_loss: 7.2598\n",
      "Epoch 3/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 6.9303\n",
      "Generating text after epoch: 2\n",
      "施世範... -> 施世範之在中國足球運動員，於公元前的兒子\n",
      "Epoch 00002: val_loss improved from 7.25977 to 7.06895, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 6.9301 - val_loss: 7.0690\n",
      "Epoch 4/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 6.6831\n",
      "Generating text after epoch: 3\n",
      "施世範... -> 施世範的在上海足球俱樂部。與妻子，在\n",
      "Epoch 00003: val_loss improved from 7.06895 to 6.95386, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 6.6831 - val_loss: 6.9539\n",
      "Epoch 5/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 6.4877\n",
      "Generating text after epoch: 4\n",
      "施世範... -> 施世範的兒子，即他的兒子，他的\n",
      "Epoch 00004: val_loss improved from 6.95386 to 6.88560, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 6.4877 - val_loss: 6.8856\n",
      "Epoch 6/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 6.3281\n",
      "Generating text after epoch: 5\n",
      "施世範... -> 施世範。卡爾王子古斯塔夫阿道夫古斯塔夫古斯塔夫古斯塔夫王子，\n",
      "Epoch 00005: val_loss improved from 6.88560 to 6.83636, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 6.3281 - val_loss: 6.8364\n",
      "Epoch 7/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 6.1929\n",
      "Generating text after epoch: 6\n",
      "施世範... -> 施世範，在阿波羅的兒子。後，是中國\n",
      "Epoch 00006: val_loss improved from 6.83636 to 6.80895, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 6.1929 - val_loss: 6.8090\n",
      "Epoch 8/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 6.0770\n",
      "Generating text after epoch: 7\n",
      "施世範... -> 施世範。被提名的父親的兒子，由香港\n",
      "Epoch 00007: val_loss improved from 6.80895 to 6.78936, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 6.0770 - val_loss: 6.7894\n",
      "Epoch 9/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.9755\n",
      "Generating text after epoch: 8\n",
      "施世範... -> 施世範和挪威。中國國家足球隊國家隊英格蘭。父親的\n",
      "Epoch 00008: val_loss improved from 6.78936 to 6.77732, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 5.9755 - val_loss: 6.7773\n",
      "Epoch 10/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.8861\n",
      "Generating text after epoch: 9\n",
      "施世範... -> 施世範。阿根廷國家隊主教練。英國下議院，是一位\n",
      "Epoch 00009: val_loss improved from 6.77732 to 6.77372, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 5.8861 - val_loss: 6.7737\n",
      "Epoch 11/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.8073\n",
      "Generating text after epoch: 10\n",
      "施世範... -> 施世範。人，並且的，其，與鄭成功\n",
      "Epoch 00010: val_loss improved from 6.77372 to 6.77214, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 5.8073 - val_loss: 6.7721\n",
      "Epoch 12/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.7380\n",
      "Generating text after epoch: 11\n",
      "施世範... -> 施世範、黃百家，在教皇。在法國的\n",
      "Epoch 00011: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.7381 - val_loss: 6.7753\n",
      "Epoch 13/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.6773\n",
      "Generating text after epoch: 12\n",
      "施世範... -> 施世範。第在荷蘭足球會會西甲。母親\n",
      "Epoch 00012: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.6773 - val_loss: 6.7787\n",
      "Epoch 14/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.6213\n",
      "Generating text after epoch: 13\n",
      "施世範... -> 施世範、陳明宗，在法國數學家，的兒子\n",
      "Epoch 00013: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.6212 - val_loss: 6.7763\n",
      "Epoch 15/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.5721\n",
      "Generating text after epoch: 14\n",
      "施世範... -> 施世範。後，其，在中國足球俱樂部。\n",
      "Epoch 00014: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.5722 - val_loss: 6.7761\n",
      "Epoch 16/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.5268\n",
      "Generating text after epoch: 15\n",
      "施世範... -> 施世範，但是，在加州理工學院，後來在公元，\n",
      "Epoch 00015: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.5268 - val_loss: 6.7861\n",
      "Epoch 17/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.4878\n",
      "Generating text after epoch: 16\n",
      "施世範... -> 施世範。成為了的，以時間被抽作。\n",
      "Epoch 00016: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.4878 - val_loss: 6.7844\n",
      "Epoch 18/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.4500\n",
      "Generating text after epoch: 17\n",
      "施世範... -> 施世範以後，在羅馬皇帝。，是一位在\n",
      "Epoch 00017: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.4501 - val_loss: 6.7859\n",
      "Epoch 19/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.4166\n",
      "Generating text after epoch: 18\n",
      "施世範... -> 施世範。日本足球俱樂部和。母親為了，\n",
      "Epoch 00018: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.4166 - val_loss: 6.7973\n",
      "Epoch 20/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.3840\n",
      "Generating text after epoch: 19\n",
      "施世範... -> 施世範後，卻去了亞歷山大馬其頓腓力二世的父親\n",
      "Epoch 00019: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.3841 - val_loss: 6.7957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3aeab4a4e0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.fit(\n",
    "    train_x, \n",
    "    train_y, \n",
    "    batch_size=512, \n",
    "    epochs=20, \n",
    "    callbacks=[LambdaCallback(on_epoch_end=on_epoch_end), checkpoint],\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.load_weights(filepath)\n",
    "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"\n",
    "    temperature 表示控制 sample 字的多樣性，越高越隨機\n",
    "    越低則越強化原本預測機率的差距，ex: [0.2, 0.5, 0.3] -> [0.009, 0.91, 0.07]\n",
    "    \"\"\"\n",
    "    if temperature <= 0:\n",
    "        return np.argmax(preds)\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generate_next(text, num_generated=10, temperature=1.0):\n",
    "    word_idxs = [word2idx(word) for word in text]\n",
    "    for i in range(num_generated):\n",
    "        prediction = rnn_model.predict(x=np.array(word_idxs))\n",
    "        idx = sample(prediction[-1], temperature)\n",
    "        word_idxs.append(idx)\n",
    "    return ''.join(idx2word(idx) for idx in word_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'呂薇。以為香港足球俱樂部，在巴黎聖日耳曼、張愚，後，被租借，其後，是埃及的父親，在羅馬天主教，在西藏。了一個德國的母親，並，是一名阿根廷，他在2012年，也是先知，他的收入中的女兒。在重慶在2009年，是波斯大流士帝國的。雖然後，以其為了最後的父親愛德華的，現任，在中國國家，在1945，在法國足球俱樂部的兒子。被阮惠之子，以其的中國足球俱樂部位置的，也是法國的行為，後來，為了，他的婚姻，在這支，也是一位意大利的兒子，在羅馬，在日本國家足球隊國家隊，為了。被劃為他在前前前753，同年，是一位的母親陳朝陳煚陳朝，為他的父親是一名生於日本國家足球隊日本職業足球會，在那裡，被殺。出身於前中華人民共和國國務院主席、費拉里，是一位是中國足球俱樂部俱樂部。與馬其頓攝政的父親，被重命名，是他的，立與所羅門王。於中國足球俱樂部，由於被暗殺。成為父親的一個了，後來，被重命名，因後來他被認為是一名，他的，是一名足球會在羅馬皇帝，分別是一個母親，與釋迦牟尼的之後，這在沿海的兒子。在她的，與英國，從美國人，被羅馬皇帝。於2008年，在羅馬皇帝，為新的，曾在英國史密斯，是加州大學洛杉磯分校。了他的兒子。被下啟。在20，以其的，在他們，在耶路撒冷的父親，在倫敦的弟弟，同時是一位前。與中國足球俱樂部上海申花的兒子，後，其，後者是一位的表現是一位是一位是一位著名的弟弟，最後，於中國足球俱樂部，在日本國家足球隊成員。他。他。是一位他的兒子。前，又被吳偉，是一位阿根廷足球俱樂部青訓。父親的兒子。為下，兩人，曾被明命帝，是一位在劍橋大學。與其為了，並與和人。的兒子，在英格蘭的女兒。中國國家足球隊成員。與懷疑的兒子，在他，在耶路撒冷的，是為了的的，為的新。以為。在上海燭龍，以4，是由前前，代表，在其，在以21歲，在這場，率領，以'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 隨機生成文章\n",
    "generate_next([idx2word(np.random.randint(vocab_size))], 500, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 參考資料\n",
    "1. https://zake7749.github.io/2016/08/28/word2vec-with-gensim/\n",
    "2. https://gist.github.com/maxim5/c35ef2238ae708ccb0e55624e9e0252b\n",
    "3. https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\n",
    "4. https://www.jianshu.com/p/e19b96908c69"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
